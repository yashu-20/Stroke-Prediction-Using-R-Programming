---
output:
  word_document: default
  html_document: default
  
---
```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))

# Install and load the tidyverse package
if (!require(tidyverse)) 
  install.packages("tidyverse")
  library(tidyverse)

library(tidymodels) # models
library(skimr) # descriptive stats
library(stringr) # works with strings
library(themis) # for SMOTE and other recipes for target balancing
install.packages("vip")
library(vip) # for variable importance
install.packages("probably")
library(probably) # for performance calibration
```

# Data set
# upon quick look at the data set
# if you set smoking_status to factor in col_types, na() won't work
# remove ID, Sex == Other
# output to a factor
```{r}
df <- 
  readr::read_csv("healthcare-dataset-stroke-data.csv", col_types = "cfdfffffddcf", na = c("Unknown", "N/A")) %>% 
  mutate(smoking_status = factor(smoking_status),
         stroke = factor(ifelse(stroke == 1, "yes", "no"), levels = c("yes", "no"))) %>% 
  select(-id)

df



## Descriptive statistics

skim(df) %>%
  yank("factor")


df <- df %>% filter(gender != "Other")

skim(df) %>%
  yank("numeric")



df %>% group_by(stroke, smoking_status) %>% 
  count()



df %>% filter(is.na(bmi)) %>% 
  group_by(stroke) %>% 
  count()



# Exploratory Data Analysis

## Quick overview

library(GGally)

# Assuming df is your dataset
ggpairs(
  df,
  aes(color = stroke, alpha = 0.2, size = 0.02),
  upper = list(continuous = wrap("cor", size = 2.5)),
  diag = list(continuous = "barDiag")
) +
  scale_color_brewer(palette = "Set1", direction = -1) +
  scale_fill_brewer(palette = "Set1", direction = -1)


## In details

### Stroke vs Age


ggplot(df, aes(stroke, age)) +
  geom_boxplot(aes(fill = stroke), alpha = 0.5, varwidth = T, notch = T) +
  geom_violin(aes(fill = stroke), alpha = 0.5) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  xlab("")




### Stroke vs Age + Gender

ggplot(df, aes(stroke, age)) + 
  geom_violin(alpha=0.3) +
  geom_jitter(alpha=0.2, size=0.8, width = 0.15, height = 0.1, aes(color = gender)) + 
  geom_boxplot(alpha = 0.2) +
  scale_color_brewer(palette = "Set2", direction = -1)


### Stroke vs Glucose

ggplot(df, aes(stroke, avg_glucose_level)) +
  geom_boxplot(aes(fill = stroke), alpha = 0.5, varwidth = T, notch = T) +
  geom_violin(aes(fill = stroke), alpha = 0.5) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  xlab("") +
  ylab("avg glucose level")


                                                 ### Stroke vs BMI
                                                 
                                                 ggplot(df, aes(stroke, bmi)) +
                                                   geom_boxplot(aes(fill = stroke), alpha = 0.5, varwidth = T, notch = T) +
                                                   geom_violin(aes(fill = stroke), alpha = 0.5) +
                                                   scale_fill_brewer(palette = "Set1", direction = -1) +
                                                   xlab("")
                                                 
                                                 
                                                
                                                 ### Age vs BMI
                                                 
                                                 
                                                 facet_names <- c("no" = "no stroke", "yes" = "stroke")
                                                 
                                                 ggplot(df, aes(age, bmi)) +
                                                   geom_point(color = "steelblue", alpha = 0.8, size = 0.5) +
                                                   facet_grid(rows = vars(stroke), labeller = as_labeller(facet_names)) +
                                                   guides()

                                                 ### Glucose vs Age + smoking
                                                 
                                                 
                                                 ggplot(df, aes(age, avg_glucose_level)) +
                                                   geom_point(aes(color = smoking_status), alpha = 0.6, size = 1) +
                                                   scale_fill_brewer(palette = "Set1", direction = -1) +
                                                   facet_grid(rows = vars(stroke), labeller = as_labeller(facet_names)) +
                                                   guides()

                                                 
                                                 ### Age vs Smoking
                                                 
                                                 
                                                 ggplot(df, aes(smoking_status, age)) +
                                                   geom_boxplot(aes(fill = stroke), alpha = 0.5, varwidth = T, notch = T) +
                                                   scale_fill_brewer(palette = "Set1", direction = -1) +
                                                   xlab("")

                                              
                                                 
                                                 ### Glucose vs BMI
                                                 
                                                 
                                                 ggplot(df, aes(avg_glucose_level, bmi)) +
                                                   geom_point(aes(color = age), alpha = 0.6, size = 1) +
                                                   scale_fill_brewer(palette = "Set1", direction = -1) +
                                                   facet_grid(rows = vars(stroke), labeller = as_labeller(facet_names)) +
                                                   guides() +
                                                   xlab("avg glucose level")
                                                 
                                          
                                                 
                                                 ### Stroke vs Gender
                                                 
                                                 
                                                 gender <- df %>% group_by(stroke, gender) %>% summarize(N=n())
                                                 
                                                 ggplot(gender, aes(stroke, N)) +
                                                   geom_bar(aes(fill=gender), alpha = 0.8, stat = "identity", position = "fill") +
                                                   scale_fill_brewer(palette = "Set2", direction = -1) +
                                                   ylab("proportion")
                                                 
                                                 
                                             
                                                 
                                                 ### Stroke vs Hypertension
                                                 
                                                 
                                                 hyptens <- df %>% group_by(stroke, hypertension) %>% summarize(N = n())
                                                 
                                                 ggplot(hyptens, aes(stroke, N)) +
                                                   geom_bar(aes(fill = hypertension), alpha = 0.8, stat = "identity", position = "fill") +
                                                   scale_fill_brewer(palette = "Set2", direction = -1) +
                                                   ylab("proportion")
                                                 
                                                 
                                               
                                                 
                                                 ### Stroke vs Heart Disease
                                                 
                                                 
                                                 heart <- df %>% group_by(stroke, heart_disease) %>% summarize(N=n())
                                                 
                                                 ggplot(heart, aes(stroke, N)) +
                                                   geom_bar(aes(fill = heart_disease), alpha = 0.8, stat = "identity", position = "fill") +
                                                   scale_fill_brewer(palette = "Set2", direction = 1) +
                                                   ylab("proportion")
                                                
                                                
                                                 
                                                 ### Stroke vs Ever Married
                                                 
                                                 
                                                 married <- df %>% group_by(stroke, ever_married) %>% summarize(N=n())
                                                 
                                                 ggplot(married, aes(stroke, N)) +
                                                   geom_bar(aes(fill = ever_married), alpha = 0.8, stat = "identity", position = "fill") +
                                                   scale_fill_brewer(palette = "Set2", direction = -1) +
                                                   ylab("proportion")
                                                 
                                                 
                                                

### Stroke vs Work Type


work <- df %>% group_by(stroke, work_type) %>% summarize(N=n())

ggplot(work, aes(stroke, N)) +
  geom_bar(aes(fill = work_type), alpha = 0.8, stat = "identity", position = "fill") +
  scale_fill_brewer(palette = "Set2", direction = 1) +
  ylab("proportion")



### Stroke vs Residence Type


residence <- df %>% group_by(stroke, Residence_type) %>% summarize(N=n())

ggplot(residence, aes(stroke, N)) +
  geom_bar(aes(fill = Residence_type), alpha = 0.8, stat = "identity", position = "fill") +
  scale_fill_brewer(palette = "Set2", direction = 1) +
  ylab("proportion")



### Stroke vs Smoking


smoking <- df %>% group_by(stroke, smoking_status) %>% summarize(N=n())

ggplot(smoking, aes(stroke, N)) +
  geom_bar(aes(fill = smoking_status), alpha = 0.8, stat = "identity", position = "fill") +
  scale_fill_brewer(palette = "Set2", direction = 1) +
  ylab("proportion")

 

### Kids and Smoking


df %>% filter(work_type == "children") %>% 
  group_by(smoking_status) %>% 
  summarise(N = n(), 
            avg.age = mean(age), 
            max.age = max(age), 
            min.age = min(age))
```



# Data preprocessing

## Stratified split

```{r}
set.seed(124)

data_split <- initial_split(df, prop = 3/4, strata = stroke)

df_train <- training(data_split)
df_test <- testing(data_split)
```

## 10-fold CV repeated 10 times

```{r}
set.seed(345)
# Stratified, repeated 10-fold cross-validation
cv_folds <- vfold_cv(df_train, strata = "stroke", v = 10, repeats = 10)

# metrics
cls_metrics <- metric_set(roc_auc, j_index)
```


## Recipe

```{r}
prep_recipe <- recipe(stroke ~ ., data = df_train) %>%
  step_impute_bag(bmi, smoking_status) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  #step_impute_bag(all_predictors()) %>% 
  step_normalize(age, avg_glucose_level, bmi) %>% 
  step_smote(stroke, over_ratio = 1, seed = 100) %>%
  check_missing(all_predictors()) %>% 
  step_zv(all_predictors())

prep_recipe
```

```{r}
# the other way is to apply the recipe to your data immediately
# prep & bake
train_data <- prep_recipe %>% 
  prep(training = df_train) %>% 
  bake(new_data = NULL) # df_train will be processed

# bake test. what about SMOTE?
test_data <- prep_recipe %>% 
  prep(training = df_test) %>% 
  bake(new_data = df_test)

# check oversampling results
train_data %>% count(stroke) # SMOTE was applied
test_data %>% count(stroke) # not applied
```

# Penalized Logistic Regression

I add one more step to the recipe - remove correlated predictors (threshold = 0.75)

```{r}
# recipe for LR
lr_recipe <- prep_recipe %>% 
  step_corr(all_predictors(), threshold = 0.75)

# set model type/engine
lr_mod <- logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")

# define the workflow
lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)

# create a tune grid
lr_reg_grid <- tibble(penalty = 10**seq(-4, 0, length.out = 30))

# train and tune the model
lr_res <- tune_grid(lr_workflow,
              grid = lr_reg_grid,
              resamples = cv_folds,
              control = control_grid(save_pred = TRUE),
              metrics = cls_metrics)

autoplot(lr_res)
```


## Choose the best model

Here you see top 5 best models based on mean AUC and ranked by penalty score

```{r}
top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 5) %>% 
  arrange(penalty) 

top_models %>% arrange(penalty)
```

I will choose a model with the highest mean AUC

```{r}
lr_best <- lr_res %>% 
  select_best(metric = "roc_auc")

lr_best
```

## ROC-AUC of the best model

```{r}
lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(stroke, .pred_yes) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```

```{r}
rf_res %>% 
  show_best(metric = "roc_auc")
```



```{r}
rf_res %>% 
  show_best(metric = "j_index")
```



```{r}
rf_best <- rf_res %>% 
  select_best(metric = "roc_auc")

rf_best
```

## ROC-AUC of the best model

```{r}
rf_auc <- rf_res %>% 
  collect_predictions(parameters = rf_best) %>% 
  roc_curve(stroke, .pred_yes) %>% 
  mutate(model = "Random Forest")

autoplot(rf_auc) # 0.8
```


# Boosted trees

## Tune


```{r}
set.seed(732)

# number of cores available on Kaggle
cores <- 4L 

# model specification
xgb_mod <- 
  boost_tree(
    trees = 50, 
    mtry = tune(), 
    min_n = tune(), 
    tree_depth = tune(), 
    learn_rate = tune(), 
    loss_reduction = tune(), 
    sample_size = tune(), 
    stop_iter = tune()) %>% 
  set_engine("xgboost", num.threads = cores) %>% 
  set_mode("classification")

# workflow
xgb_cv_wf <- workflow() %>% 
  add_model(xgb_mod) %>% 
  add_recipe(prep_recipe)

# tune models, this takes time
xgb_res <- tune_grid(xgb_cv_wf,
            grid = 25,
            resamples = cv_folds,
            control = control_grid(save_pred = TRUE),
            metrics = cls_metrics)
```

## Tuning results

```{r}
autoplot(xgb_res)
```

## Choose the best model



```{r}
xgb_res %>% 
  show_best(metric = "roc_auc")
```


```{r}
xgb_res %>% 
  show_best(metric = "j_index")
```



```{r}
xgb_best <- xgb_res %>% 
  select_best(metric = "roc_auc")

xgb_best
```

## ROC-AUC of the best model

```{r}
xgb_auc <- xgb_res %>% 
  collect_predictions(parameters = xgb_best) %>% 
  roc_curve(stroke, .pred_yes) %>% 
  mutate(model = "Boosted Trees")

autoplot(xgb_auc)
```

# Compare Logistic Regression, Random Forest and Boosted Trees models

```{r}
bind_rows(rf_auc, lr_auc, xgb_auc) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 0.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)

```



# The final fit



```{r}
# the last model
last_mod <- logistic_reg(penalty = lr_best$penalty, mixture = 1) %>% 
  set_engine("glmnet")  %>% 
  set_mode("classification")

# the last workflow: based on LR
last_wf <- 
  lr_workflow %>% 
  update_model(last_mod)

# the last fit
set.seed(345)
last_fit <- 
  last_wf %>% 
  last_fit(data_split)
```

## Accuracy and AUC of the final fit

```{r}
last_fit %>% 
  collect_metrics()
```

## Variable importance

```{r}
last_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 15)
```


## ROC curve on the test data set

```{r}
last_fit %>% 
  collect_predictions() %>% 
  roc_curve(stroke, .pred_yes) %>% 
  autoplot()

```


## Balancing performance by choosing optimal probability cut-off.


```{r}
# collect sens, spec, j-index at various cut-offs
threshold_data <- 
  last_fit %>%
  collect_predictions() %>%
  threshold_perf(stroke, .pred_yes, thresholds = seq(0.0, 1, by = 0.05)) %>% 
  filter(.metric != "distance") %>%
  mutate(group = case_when(
    .metric == "sens" | .metric == "spec" ~ "1",
    TRUE ~ "2"
  ))

# find max j-index
max_j_index_threshold <- threshold_data %>%
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold)

# plot metrics v cut-offs
ggplot(threshold_data, aes(x = .threshold, y = .estimate, color = .metric, alpha = group)) +
  geom_line(size=1) +
  #theme_minimal() +
  #scale_color_viridis_d(end = 0.9) +
  scale_color_brewer(palette = "Set1") +
  scale_alpha_manual(values = c(.4, 1), guide = "none") +
  geom_vline(xintercept = max_j_index_threshold, alpha = .8, color = "grey30", linetype = "longdash") +
  labs(
    x = "Probability",
    y = "Metric Estimate",
    title = "Optimal probability cut-off"
  )
```

j-index is at its maximum at probability cut-off `r max_j_index_threshold`. This value can be chosen to calculate the final confusion matrix.

## Confusion Matrix

```{r}
pred_optimized <- last_fit %>%
  collect_predictions() %>% 
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_yes, 
      levels = levels(stroke), 
      threshold = max_j_index_threshold
    )
  ) %>%
  select(stroke, contains(".pred"))

cm_optimized <- pred_optimized %>% 
  conf_mat(truth = stroke, estimate = .pred)

autoplot(cm_optimized, type = "heatmap")
```

## All performance metrics

With probability cut-off `r max_j_index_threshold`

```{r}
summary(cm_optimized)
```

